{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_path = 'orbits/detections'\n",
    "err_files = os.listdir(errs_path)\n",
    "err_files = [f for f in err_files if f.endswith('_errs.npy')]\n",
    "\n",
    "detections_path = 'orbits/detections'\n",
    "detections_files = os.listdir(detections_path)\n",
    "detections_files = [f for f in detections_files if f.endswith('_detections.npy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_errs_and_detections(err_file):\n",
    "    detections_file = err_file.replace('_errs', '_all_detections')\n",
    "    if detections_file in detections_files:\n",
    "        errs = np.load(os.path.join(errs_path, err_file))\n",
    "        detections = np.load(os.path.join(detections_path, detections_file))\n",
    "        return errs, detections, detections_file\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errs_float(errs, detections):\n",
    "    detections = np.array(detections)\n",
    "    ts = np.unique(detections[:,0])\n",
    "    regions = errs[:,4]\n",
    "    errs_left = errs[:, :4]\n",
    "    errs_right = errs[:, 5:]\n",
    "    errs_float = np.hstack([errs_left, errs_right])\n",
    "    errs_float = np.float64(errs_float)\n",
    "    return ts, regions, errs_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def remove_timesteps_with_few_detections(errs_float, detections, ts, threshold, regions):\n",
    "    # Find the timesteps with less than 5 detections\n",
    "    timesteps_to_remove = []\n",
    "    for t in ts:\n",
    "        err_t = errs_float[errs_float[:,0] == t]\n",
    "        dets_t = detections[detections[:,0] == t]\n",
    "        if len(dets_t) < threshold:\n",
    "            timesteps_to_remove.append(t)\n",
    "\n",
    "    indexes_to_keep = ~np.isin(detections[:,0], timesteps_to_remove)\n",
    "    \n",
    "    # Remove the timesteps from err_t, dets_t, and ts\n",
    "    err_t = errs_float[indexes_to_keep]\n",
    "    dets_t = detections[indexes_to_keep]\n",
    "    ts = np.unique(dets_t[:,0])\n",
    "    regions = regions[indexes_to_keep]\n",
    "    return err_t, dets_t, ts, regions\n",
    "    # err_t = np.array([err for err in err_t if err[0] not in timesteps_to_remove])\n",
    "    # dets_t = np.array([det for det in dets_t if det[0] not in timesteps_to_remove])\n",
    "    # ts = np.array([t for t in ts if t not in timesteps_to_remove])\n",
    "    # return err_t, dets_t, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_detections_outside_image_frame(detections):   \n",
    "    frame_width = 4608\n",
    "    frame_height = 2592\n",
    "\n",
    "    # Get the x and y coordinates from the detections\n",
    "    x_coords = detections[:, 3]\n",
    "    y_coords = detections[:, 4]\n",
    "\n",
    "    # Find the indices of detections outside of the image frame\n",
    "    outside_indices = np.where((x_coords < 0) | (x_coords >= frame_width) | (y_coords < 0) | (y_coords >= frame_height))[0]\n",
    "\n",
    "    return outside_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_detections_outside_image_frame(err_t, dets_t, regions, outside_indices):\n",
    "    # Remove the detections outside from err_t, dets_t\n",
    "    err_t = np.delete(err_t, outside_indices, axis=0)\n",
    "    dets_t = np.delete(dets_t, outside_indices, axis=0)\n",
    "    regions = np.delete(regions, outside_indices, axis=0)\n",
    "\n",
    "    return err_t, dets_t, regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bad_classes(err_t, dets_t, regions, errs_float, detections):\n",
    "    err_t_bc = err_t\n",
    "    dets_t_bc = dets_t\n",
    "    regions_bc = regions\n",
    "    for region in np.unique(regions):\n",
    "        #region_indices = np.where(regions_bc == region)\n",
    "        #region_errs = errs_float[region_indices]\n",
    "        #region_dets = detections[region_indices]\n",
    "        #region_ts = np.unique(region_dets[:,0])\n",
    "\n",
    "        cls = err_t_bc[:,3] * (regions == region)\n",
    "        bad_classes = np.load('bad_classes/' + region + '_bad_classes.npy')\n",
    "        \n",
    "        if len(bad_classes) > 0:\n",
    "            bad_class_indices = np.isin(cls, bad_classes)\n",
    "\n",
    "            # Remove bad classes from err_t_bc\n",
    "            err_t_bc = err_t_bc[~bad_class_indices]\n",
    "\n",
    "            # Remove corresponding detections from dets_t_bc\n",
    "            dets_t_bc = dets_t_bc[~bad_class_indices]\n",
    "\n",
    "            # Remove corresponding regions from regions_bc\n",
    "            regions_bc = regions_bc[~bad_class_indices]\n",
    "\n",
    "            regions = regions[~bad_class_indices]\n",
    "\n",
    "    if len(err_t_bc) == 0:\n",
    "        #print('No detections left after removing bad classes')\n",
    "        return None, None, None    \n",
    "    else:\n",
    "        #print('Detections left after removing bad classes')\n",
    "        return err_t_bc, dets_t_bc, regions_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_lists(ts, dets_t_bc):\n",
    "    outlier_lists = {}\n",
    "    for t in ts:\n",
    "        dets_t2 = dets_t_bc[dets_t_bc[:,0] == t]\n",
    "        dets_t2_x_y_lon_lat = dets_t2[:, [3, 4, 1, 2]]\n",
    "        outlier_lists[t] = dets_t2_x_y_lon_lat.tolist()\n",
    "    return outlier_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def remove_outliers(outlier_list, residual_threshold=0.0005):\n",
    "    outlier_arr = np.array(outlier_list)\n",
    "    xs = outlier_arr[:,0]\n",
    "    ys = outlier_arr[:,1]\n",
    "    lons = outlier_arr[:,2]\n",
    "    lats = outlier_arr[:,3]\n",
    "    # Call the function to fit the model\n",
    "    predicted_lon = fit_lon(xs, ys, lons)\n",
    "    predicted_lat = fit_lat(xs, ys, lats)\n",
    "    residuals = np.linalg.norm(np.column_stack((predicted_lon, predicted_lat)) - np.column_stack((lons, lats)), axis=1)\n",
    "    inlier_indexes = np.where(residuals < residual_threshold)\n",
    "    return inlier_indexes\n",
    "\n",
    "# Define a function to fit the model and predict lon\n",
    "def fit_lon(xs, ys, lons):\n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly_features.fit_transform(np.column_stack((xs, ys)))\n",
    "\n",
    "    # Fit the linear regression model\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_poly, lons)\n",
    "\n",
    "    # Predict lon based on x and y\n",
    "    predicted_lon = lin_reg.predict(poly_features.transform(np.column_stack((xs, ys))))\n",
    "\n",
    "    return predicted_lon\n",
    "\n",
    " # Define a function to fit the model and predict lat\n",
    "def fit_lat(xs, ys, lats):\n",
    "    # Create polynomial features\n",
    "    poly_features = PolynomialFeatures(degree=2)\n",
    "    X_poly = poly_features.fit_transform(np.column_stack((xs, ys)))\n",
    "\n",
    "    # Fit the linear regression model\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_poly, lats)\n",
    "\n",
    "    # Predict lat based on x and y\n",
    "    predicted_lat = lin_reg.predict(poly_features.transform(np.column_stack((xs, ys))))\n",
    "\n",
    "    return predicted_lat\n",
    "\n",
    "    # # Call the function to fit the model\n",
    "    # degree = 2  # Set the degree of the polynomial\n",
    "    # model = fit_lon_lat(xs, ys, lons, lats, degree)\n",
    "\n",
    "    # # Use the model to predict inliers\n",
    "    # predicted_lonlats = model.predict(np.column_stack((xs,ys), axis=1))\n",
    "    # residuals = np.linalg.norm(predicted_lonlats - np.column_stack((lons, lats)), axis=1)\n",
    "    # inlier_indexes = np.where(residuals < 0.0005)\n",
    "    # return inlier_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inliers(ts, dets_t2, errs_t2, outlier_lists, threshold=0.0005):\n",
    "    inlier_dets = []\n",
    "    inlier_errs = []\n",
    "    for t in ts:\n",
    "        outlier_list = outlier_lists[t]\n",
    "        inlier_indexes = remove_outliers(outlier_list, threshold)\n",
    "        dets3 = np.array(dets_t2)[inlier_indexes]\n",
    "        errs3 = np.array(errs_t2)[inlier_indexes]\n",
    "        if len(dets3) > 0:\n",
    "            for det, err in zip(dets3, errs3):\n",
    "                if len(det) > 0:\n",
    "                    inlier_dets.append(det)\n",
    "                    inlier_errs.append(err)\n",
    "        else:\n",
    "            continue\n",
    "    if len(inlier_dets) < 0:\n",
    "        return None, None\n",
    "    return np.array(inlier_dets), np.array(inlier_errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dets(dets3, detection_file, thresh):\n",
    "    if not os.path.exists('orbits/detections/newdets/thresh' + str(thresh)):\n",
    "        os.makedirs('orbits/detections/newdets/thresh' + str(thresh))\n",
    "    np.save('orbits/detections/newdets/' + 'thresh' + str(thresh) + '/' + detection_file, dets3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errs_for_file(thresh, err_file):\n",
    "    errs, detections, detection_file = load_errs_and_detections(err_file)\n",
    "    if len(detections) == 0:\n",
    "        save_dets(detections, detection_file, thresh)\n",
    "        return None\n",
    "        \n",
    "    ts, regions, errs_float = get_errs_float(errs, detections)\n",
    "    err_t, dets_t, ts, regions_t = remove_timesteps_with_few_detections(errs_float, detections, ts, 5, regions)\n",
    "    outside_indices = remove_detections_outside_image_frame(dets_t)\n",
    "    err_t, dets_t, regions_t = delete_detections_outside_image_frame(err_t, dets_t, regions_t, outside_indices)\n",
    "    err_t_bc, dets_t_bc, regions_t_bc = remove_bad_classes(err_t, dets_t, regions_t, errs_float, detections)\n",
    "    if err_t_bc is None:\n",
    "        save_dets(np.array([]), detection_file, thresh)\n",
    "        return None\n",
    "    err_t2, dets_t2, ts2, regions_t2 = remove_timesteps_with_few_detections(err_t_bc, dets_t_bc, ts, 3, regions_t_bc)\n",
    "    outlier_lists = get_outlier_lists(ts2, dets_t2)\n",
    "    inlier_dets, inlier_errs = get_inliers(ts2, dets_t2, err_t2, outlier_lists, thresh)\n",
    "    #print(len(inlier_dets))\n",
    "    if inlier_dets is None or len(inlier_dets) < 2:\n",
    "        save_dets(np.array([]), detection_file, thresh)\n",
    "        return None\n",
    "    # print('Mean x error:', np.mean(inlier_errs[:, 1]))\n",
    "    # print('Mean y error:', np.mean(inlier_errs[:, 2]))\n",
    "    # print('Median x error:', np.median(inlier_errs[:, 1]))\n",
    "    # print('Median y error:', np.median(inlier_errs[:, 2]))\n",
    "    # print('Max x error:', np.max(inlier_errs[:, 1]))\n",
    "    # print('Max y error:', np.max(inlier_errs[:, 2]))\n",
    "    else:\n",
    "        save_dets(inlier_dets, detection_file, thresh)\n",
    "    \n",
    "    return [np.mean(inlier_errs[:, 1]), np.mean(inlier_errs[:, 2]), np.median(inlier_errs[:, 1]), np.median(inlier_errs[:, 2]), np.max(inlier_errs[:, 1]), np.max(inlier_errs[:, 2]), len(inlier_dets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:04<00:00, 64.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 10000\n",
      "Number of detections: 1815916\n",
      "Mean x error: 15.00580063970503\n",
      "Mean y error: 14.633367070577341\n",
      "Median x error: 5.666517899601331\n",
      "Median y error: 6.252723480057881\n",
      "Max x error: 1913.5657886683775\n",
      "Max y error: 2398.5742477296853\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "errors_per_thresh = {}\n",
    "\n",
    "#p = Pool(8)\n",
    "\n",
    "for thresh in tqdm(np.linspace(0.0001, 0.0001, 1)):\n",
    "    thresh = 10000\n",
    "    errors_per_file = []\n",
    "    for err_file in err_files:\n",
    "        err = get_errs_for_file(thresh, err_file)\n",
    "        if err is not None:\n",
    "            errors_per_file.append(err)\n",
    "    # errors_per_file = p.map(get_errs_for_file, err_files[:50])\n",
    "    # p.close()\n",
    "    # p.join()\n",
    "    errors_per_thresh[thresh] = [np.mean([errors[0] for errors in errors_per_file]), np.mean([errors[1] for errors in errors_per_file]), np.median([errors[2] for errors in errors_per_file]), np.median([errors[3] for errors in errors_per_file]), np.max([errors[4] for errors in errors_per_file]), np.max([errors[5] for errors in errors_per_file]), np.sum([errors[6] for errors in errors_per_file])]\n",
    "    \n",
    "\n",
    "    # for err_file in err_files[:50]:\n",
    "    #     errs, detections, detection_file = load_errs_and_detections(err_file)\n",
    "    #     if len(detections) == 0:\n",
    "    #         save_dets(detections, detection_file)\n",
    "    #         continue\n",
    "            \n",
    "    #     ts, regions, errs_float = get_errs_float(errs, detections)\n",
    "    #     err_t, dets_t, ts, regions_t = remove_timesteps_with_few_detections(errs_float, detections, ts, 5, regions)\n",
    "    #     outside_indices = remove_detections_outside_image_frame(dets_t)\n",
    "    #     err_t, dets_t, regions_t = delete_detections_outside_image_frame(err_t, dets_t, regions_t, outside_indices)\n",
    "    #     err_t_bc, dets_t_bc, regions_t_bc = remove_bad_classes(err_t, dets_t, regions_t, errs_float, detections)\n",
    "    #     if err_t_bc is None:\n",
    "    #         save_dets(np.array([]), detection_file)\n",
    "    #         continue\n",
    "    #     err_t2, dets_t2, ts2, regions_t2 = remove_timesteps_with_few_detections(err_t_bc, dets_t_bc, ts, 3, regions_t_bc)\n",
    "    #     outlier_lists = get_outlier_lists(ts2, dets_t2)\n",
    "    #     inlier_dets, inlier_errs = get_inliers(ts2, dets_t2, err_t2, outlier_lists, thresh)\n",
    "    #     #print(len(inlier_dets))\n",
    "    #     if inlier_dets is None or len(inlier_dets) < 2:\n",
    "    #         save_dets(np.array([]), detection_file)\n",
    "    #         continue\n",
    "    #     # print('Mean x error:', np.mean(inlier_errs[:, 1]))\n",
    "    #     # print('Mean y error:', np.mean(inlier_errs[:, 2]))\n",
    "    #     # print('Median x error:', np.median(inlier_errs[:, 1]))\n",
    "    #     # print('Median y error:', np.median(inlier_errs[:, 2]))\n",
    "    #     # print('Max x error:', np.max(inlier_errs[:, 1]))\n",
    "    #     # print('Max y error:', np.max(inlier_errs[:, 2]))\n",
    "    #     else:\n",
    "    #         save_dets(inlier_dets, detection_file)\n",
    "        \n",
    "    #     errors_per_file[err_file] = [np.mean(inlier_errs[:, 1]), np.mean(inlier_errs[:, 2]), np.median(inlier_errs[:, 1]), np.median(inlier_errs[:, 2]), np.max(inlier_errs[:, 1]), np.max(inlier_errs[:, 2]), len(inlier_dets)]\n",
    "    #     #errors_per_thresh[thresh] = [np.mean(inlier_errs[:, 1]), np.mean(inlier_errs[:, 2]), np.median(inlier_errs[:, 1]), np.median(inlier_errs[:, 2]), np.max(inlier_errs[:, 1]), np.max(inlier_errs[:, 2]), len(inlier_dets)]\n",
    "    # errors_per_thresh[thresh] = [np.mean([errors_per_file[err_file][0] for err_file in errors_per_file]), np.mean([errors_per_file[err_file][1] for err_file in errors_per_file]), np.median([errors_per_file[err_file][2] for err_file in errors_per_file]), np.median([errors_per_file[err_file][3] for err_file in errors_per_file]), np.max([errors_per_file[err_file][4] for err_file in errors_per_file]), np.max([errors_per_file[err_file][5] for err_file in errors_per_file]), np.sum([errors_per_file[err_file][6] for err_file in errors_per_file])]\n",
    "    # errors_per_file = {}\n",
    "#print(errors_per_thresh)\n",
    "for thresh in errors_per_thresh:\n",
    "    print('Threshold:', thresh)\n",
    "    print('Number of detections:', errors_per_thresh[thresh][6])\n",
    "    print('Mean x error:', errors_per_thresh[thresh][0])\n",
    "    print('Mean y error:', errors_per_thresh[thresh][1])\n",
    "    print('Median x error:', errors_per_thresh[thresh][2])\n",
    "    print('Median y error:', errors_per_thresh[thresh][3])\n",
    "    print('Max x error:', errors_per_thresh[thresh][4])\n",
    "    print('Max y error:', errors_per_thresh[thresh][5])\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argus1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
